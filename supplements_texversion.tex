%! language = Latex
\section{Summary statistics for the final study sample}
\label{cha:summary-statistics}
\begin{table}[!htp]
    \begin{center}
        \begin{subtable}[c]{0.6\textwidth}
            \begin{center}
                \begin{tabular}{rc|cc}
                    &        & {\textbf{\acs{mdd}}} & {\textbf{\acs{hc}}} \\ \cline{2-4}
                    & n      & 934                  & 934                 \\ \cline{2-4}
                    \multirow{2}{*}{\textbf{Sex}}     & female & 556                  & 548                 \\
                    & male   & 378                  & 368                 \\ \cline{2-4}
                    \multirow{3}{*}{\textbf{Scanner}} & 1      & 285                  & 512                 \\
                    & 2      & 395                  & 236                 \\
                    & 3      & 254                  & 186                 \\
                \end{tabular}
                \subcaption{Summary of sample size (n), sex and scanner site.}
            \end{center}
        \end{subtable}

        \vspace{5mm}

        \begin{subtable}[c]{0.8\textwidth}
            \begin{center}
                \begin{tabular}{rr|SSSS}
                    &                     & {\textbf{Mean}} & {\textbf{SD}} & {\textbf{Min}} & {\textbf{Max}} \\ \cline{2-6}
                    \multirow{2}{*}{\textbf{\acs{mdd}}} & Age ($n=934$)       & 37.76           & 12.94         & 16             & 65             \\
                    & \acs{tiv} ($n=933$) & 1575.94         & 152.97        & 1115.00        & 2189.00        \\  \cline{2-6}
                    \multirow{2}{*}{\textbf{\acs{hc}}}  & Age ($n=934$)       & 34.15           & 12.42         & 17             & 65             \\
                    & \acs{tiv} ($n=933$) & 1575.61         & 156.38        & 1146.23        & 2706.76        \\
                \end{tabular}
                \subcaption{Summage of Age (in years) and \acs{tiv} (\acl{tiv}).}
            \end{center}
        \end{subtable}

        \vspace{6pt}
        \caption[Summary statistics for the final study sample.]{Summary statistics for the final study sample. \\
        \footnotesize
        \setlength{\tabcolsep}{4pt}
        \renewcommand{\arraystretch}{1.0}
            \begin{tabular}{llll}
                \hspace{-6pt} Abbreviations: & \acs{hc}  & - & \acl{hc}  \\
                & \acs{mdd} & - & \acl{mdd} \\
            \end{tabular}
        }
    \end{center}
\end{table}

\FloatBarrier


\section{Predictive Analytics Competition 2018}
\label{cha:pac-2018}
The medical machine learning lab from Prof. Dr. Tim Hahn invited teams from all over the world to develop a model classifying patients suffering from \ac{mdd} and \ac{hc} individuals based on structural Magnetic Resonance Imaging (sMRI) data. This competition was called \emph{Predictive Analytics Competition 2018} (\acs{pac} 2018).

\subsection*{Data}
The data for this competition - comprising structured \ac{mri} datasets with and without MDD from $N\,=\,\num{2240}$ subjects - was provided by the \emph{Institute of Translational Psychiatry}, Münster.
The images were preprocessed in advanced with the SPM toolbox CAT-12  (Matlab 9.0 / SMP12 rev. 6685 / CAT12 v.1184)  and quality checked. The participants got, additional to the diagnosis, the age, gender, \ac{tiv} and the scanner-site to consider them as covariates.

The data was split into a training and test set in advance (Table~\ref{tab:pac_datasplit}). The test set was held back and only used in the final step to designate the winner.

\begin{table}[!ht]
    \renewcommand{\arraystretch}{1.4}

    \begin{center}
        \begin{tabular}{rS[table-format=4.0]S[table-format=3.0]}
            \multicolumn{1}{c}{} & \textbf{Training} & \textbf{Test} \\
            \acs{mdd}            & 1033              & 273           \\
            \acs{hc}             & 759               & 175           \\ \cline{2-3}
            \textbf{Total}       & 1792              & 448
        \end{tabular}
        \vspace{6pt}
        \caption[Split between training and test data for the \acs{pac} 2018.]{Split between training and test data for the \ac{pac} 2018. \\

        \vspace{-6pt}
        \setlength{\tabcolsep}{4pt}
        \renewcommand{\arraystretch}{1.0}
            \begin{tabular}{llll}
                \hspace{-6pt} Abbreviations: & \acs{hc}  & - & \acl{hc}  \\
                & \acs{mdd} & - & \acl{mdd} \\
            \end{tabular}
            \label{tab:pac_datasplit}
        }
    \end{center}
\end{table}


\subsection*{Timeline}

\begin{table}[H]
    \renewcommand{\arraystretch}{1.4}
    \begin{center}
        \begin{tabular}{rrll}
            Registration opened:           & \nth{1}  & February & 2018 \\
            Training data available:       & \nth{1}  & March    & 2018 \\
            Test data available:           & \nth{27} & April    & 2018 \\
            Test prediction upload opened: & \nth{4}  & May      & 2018 \\
            Test prediction upload closed: & \nth{31} & May      & 2018 \\
        \end{tabular}
    \end{center}
\end{table}

The \enquote{\ac{pac} Award Winner 2018} was announced in a ceremony held at annually meeting of the \emph{Organization for Human Brain Mapping} (OHBM) in Singapore at the \nth{21} June 2018.


\subsection*{Results}
In total 49 teams registered with at least 170 participants. The winner was determined by the highest balanced accuracy score on the held-back test set. The team with the highest score was \enquote{paranoidandroid} (Table\ref{tab:top5pac2018}) and won the \ac{pac} 2018 Award.

\begin{table}[!h]
    \renewcommand{\arraystretch}{1.4}
    \begin{center}
        \begin{tabular}{clSSS}
            & \multicolumn{1}{l}{\textbf{Team}} & \textbf{BA} & \textbf{TPR} & \textbf{TNR} \\ \cline{2-5}
            \nth{1} & paranoidandroid                   & 0.65        & 0.53         & 0.77         \\
            \nth{2} & utastoot                          & 0.64        & 0.51         & 0.77         \\
            \nth{3} & berlin\_brain\_decoders           & 0.64        & 0.58         & 0.69         \\
            \nth{4} & depression                        & 0.63        & 0.59         & 0.67         \\
            \nth{5} & neuronauts\_p                     & 0.63        & 0.61         & 0.64
        \end{tabular}
        \vspace{6pt}
        \caption[Test results on the held-back test set by the top five teams at the \ac{pac} 2018.]{Test results on the held-back test set by the top five teams at the \ac{pac} 2018. \\

        \vspace{-6pt}
        \setlength{\tabcolsep}{4pt}
        \renewcommand{\arraystretch}{1.0}
            \begin{tabular}{llll}
                \hspace{-6pt} Abbreviations: & BA  & - & balanced accuracy                \\
                & TPR & - & true positive rate (sensitivity) \\
                & TNR & - & true negative rate (specificity) \\
            \end{tabular}

        }
        \label{tab:top5pac2018}
    \end{center}
\end{table}

\FloatBarrier


\section{Additional tabular presentations}
This section contains the tabular presentation of the graphical visualized data in the paper.

\input{supplements_chances_and_stats_tables.tex}
\FloatBarrier


\section{Influence of the scanner distribution}
\label{cha:influence-of-scanner-distribution}
Scanner site distributions were not well balanced in the \ac{pac} sample.
This imbalance was even stronger in our randomly drawn sub-samples. To determine the influence of the different scanner-sites on model accuracy, we took the same methodical approach that we used for the “train sample size effect analysis” and determined the scanner distribution for each set. Following, we calculated Spearman’s rho between the scanner-distribution and the accuracy of the hold-out test set ($n=300$). The scanner-distribution for each set was approximated using Gini’s index. Here, we show that the scanner distribution has a statistically significant influence on test set accuracy but explains only \SI{0.79}{\percent} of the variance.


\FloatBarrier


\section{Adjustment of SVM regularization based on sample size}
\label{cha:adjustment-svm-regularization}
The regularization of a linear \ac{svm} depends on the absolute number of outliers in a sample. To exclude the possibility that the use of default hyperparameters (a constant value of $C = 1$) caused the effect that we observed, we have adjusted the \ac{svm} regularization (our $C$ hyperparameter) based on the size of each analyses sub-sample. In this adjustment, a constant value $k$ is divided by the sample size. To approximate the default parameter $C=1$ on average, we have set $k=75$. For example, $C$ would be $C = 100/75 = \num{1.33}$ for a sample size of $n=100$. In this case, the adjusted regularization did not deliver results as good as what we observed with $C=1$ (see Figure~\ref{fig:adj_c_overall},~\ref{fig:adj_c_test}). Therefore, we conclude that the default value of $C=1$ across changing N values did not increase the probability of misestimating accuracy as sample size decreased.

% Supplement Figure 1
\begin{figure}[ht]
    \captionsetup[subfigure]{justification=justified,singlelinecheck=false}
    \begin{subfigure}[t]{0.61\textwidth}
        \input{images/overall_set_size_svm_adj_c_chances.pgf}
        \caption{Probabilities for linear \acp{svm} to yield an accuracy exceeding a certain threshold as a function of sample size employing \ac{loocv}.}
    \end{subfigure}
    \hspace{3.0mm}
    \begin{subfigure}[t]{0.34\textwidth}
        \input{images/overall_set_size_svm_adj_c_stats.pgf}
        \caption{Minimum, maximum and mean results for the linear \acp{svm} as a function of sample size employing \ac{loocv}. }
    \end{subfigure}
    \caption[Effects of varying overall sample sizes with an adjusted $C$ parameter.]{Effects of varying overall sample sizes employing \ac{loocv} with an adjusted $C$ parameter with $C=\frac{75}{\text{sample size}}$.}
    \label{fig:adj_c_overall}
\end{figure}

% Supplement Figure 2
\begin{figure}[ht]
    \captionsetup[subfigure]{justification=justified,singlelinecheck=false}
    \begin{subfigure}[t]{0.61\textwidth}
        \input{images/train_set_size_svm_adj_c_chances.pgf}
        \caption{Probabilities for linear \acp{svm} to yield an accuracy exceeding a certain threshold as a function of training sample size.}
    \end{subfigure}
    \hspace{3.0mm}
    \begin{subfigure}[t]{0.34\textwidth}
        \input{images/train_set_size_svm_adj_c_stats.pgf}
        \caption{Minimum, maximum and mean results for the linear \acp{svm} as a function of training sample size.}
    \end{subfigure}
    \caption[Effects of varying train sample sizes with an adjusted $C$ parameter.]{Results as a function of training set sizes with a fixed test set size of $N = 300$ and an adjusted $C$ parameter with $C=\frac{75}{\text{sample size}}$.}
    \label{fig:adj_c_test}
\end{figure}
\FloatBarrier


\section{Alternative Machine Configurations}
\label{cha:alternative-machine-configurations}
To exclude the possibility that the observed effects can only be traced back to our specific configuration, we have tested other usual configurations. The configurations consist of a preprocessing and a classification. In the preprocessing step, we used a method for reduction of feature space and a method for features selection. The reduction of the feature space was achieved with a \ac{pca}, where only a certain number the first components were used. Afterwards, for feature selection, an ANOVA was calculated and a specific number of feature beginning with the highest F-value were taken. The actual configuration used for preprocessing is listed in Table~\ref{tab:preprocessing}.
For the classification, we chose three specific machines:
\begin{enumerate}
    \item An \ac{svm} with a linear kernel and default parameter. ($C = \num{1.0}$)
    \item An \ac{svm} with an \ac{rbf} kernel and default parameter ($C = \num{1.0}$; $\gamma = 1/n_\text{feature}$)
    \item A Random Forrest and default parameter ($n_\text{estimators}=\num{100}$)
\end{enumerate}

In combination with the preprocessing, this results in 48 configurations. Since the found effect is limited to the test set size, we have only repeated our analyses for the test set for each of these configurations.

\begin{table}[!htp]
    \begin{center}

        \begin{tabular}{rr|ccccc}
            & & \multicolumn{5}{c}{\textbf{\acs{pca} $n_\text{components}$}} \\
            &             & no       & all      & \num{500} & \num{50} & \num{10} \\
            \cline{2-7}
            \multirow{6}{*}{{\textbf{ANOVA $k_\text{best}$}}} & no & $\times$ & $\times$ & $\times$ & $\times$
            & $\times$
            \\
            & \num{10}    & $\times$ & $\times$ & $\times$  & $\times$ &          \\
            & \num{100}   & $\times$ & $\times$ & $\times$  &          &          \\
            & \num{1000}  & $\times$ & $\times$ &           &          &          \\
            & \num{10000} & $\times$ &          &           &          &          \\
            & \num{50000} & $\times$ &          &           &          &          \\

        \end{tabular}
        \vspace{6mm}
        \caption[Configurations for the preprocessing]{The $\times$ marks the used combinations of configurations for the preprocessing. The \emph{no}-label means that this preprocessing step were left out.}
        \label{tab:preprocessing}
    \end{center}
\end{table}

\FloatBarrier

\subsection{Results}
\label{cha:alternative-machine-configuration-results}
The results are comparable to the originally used configuration, an \ac{svm} with a linear kernel and no preprocessing (see Figure~\ref{fig:no_PCA_no_selection_RandomForest} to~\ref{fig:PCA_all_components_1000_best_selected_LinearSVC} and Table~\ref{tab:no_PCA_no_selection_RandomForest} to~\ref{tab:PCA_all_components_1000_best_selected_LinearSVC}). The results thus underline a generally valid character of the findings.
An outlier in the results can be found for a specific configuration, a \ac{pca} with 10 components and the \ac{svm} with an \ac{rbf} kernel (see Figure~\ref{fig:PCA_10_components_no_selection_SVC} and Table~\ref{tab:PCA_10_components_no_selection_SVC}). This result can be explained due to overfitting, the machine constantly returns one constant class as a prediction.
\FloatBarrier

\subsubsection{Graphical results representation}

\input{supplements_alternative_machines_graphical.tex}

\FloatBarrier

\subsubsection{Tabular results representation}
\input{supplements_alternative_machines_tabular.tex}

